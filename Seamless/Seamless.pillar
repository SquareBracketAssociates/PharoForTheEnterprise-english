! Seamless: A Reflective Middleware for Pharo (DRAFT) 

Seamless {{{latex:\footnote{\url{http://ss3.gemstone.com/ss/Seamless.html}} }}} 
is a reflective communication middleware for Pharo
that aims to facilitate the prototyping of distributed applications.
It provides developer friendly abstractions and syntactic sugar
for an ''out-of-the-box'' Pharo to Pharo communication experience.
After prototyping your application, Seamless lets you easily 
profile and tweak communication settings such as distribution and
serialization policies for optimizing performance and avoid common
distribution caveats. This Chapter covers version 0.4 of Seamless 
for Pharo 3.0 and will be updated frequently towards version 1.0 (stable release).

''Note: Final version should present a whole prototyping-profiling-tweaking-deployment cycle for one of the examples (plus ui for logging/profiling facilities)''

!!Wait: Reflective What ?

''The first thing we do, let's kill all the lawyers'' \-\- from "Henry VI", Shakespeare

A communication middleware is a networking solution (such as a library or a framework) that aims
to hide some of the complicated networking setup (low-level details of socket management, remote method
invocation, naming etc) from the developer. A reflective communication middleware is the more dynamic 
variant of such a system whose implementation relies on run-time reflection and can thus be itself adapted and configured
at runtime {{{latex:\footnote{For more info on reflective middleware, you can read this overview by Fabio Kon et al: \url{http://www.inf.ufg.br/~fmc/papers/CACM-ReflectiveMiddleware-no-access.pdf}} }}}. 
Seamless is such a reflective middleware for Pharo and as a project can be considered a descendent of Remote Smalltalk 
{{{latex:\footnote{\url{http://www.squeaksource.com/rST.html}} }}} 
which itself was preceded by projects such as OpenCorba {{{latex:
\footnote{\url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.79.1783}}
}}} and Distributed Smalltalk {{{latex:
\footnote{\url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.7323}}
}}}. It was born as an engineering prerequisite for a research prototype on 
remote debugging and has since be used on and off internally by other RMoD projects at INRIA. 

From the point of view of the Pharo developer Seamless aspires to be \- eventually \- what RMI and DCOM is for Java and the .NET platforms respectively while leveraging the reflective and dynamic nature of our environment. Seamless may be distinguished from other solutions in that:

- It targets the Pharo environment and strives to integrate with its core facilities (ie available serialization solutions like Fuel, proxy implementations like Ghost etc)
- It provides abstractions, syntactic carbohydrates (sugar) and programming facades to make the prototyping of distributed applications feel ''out-of-the-box''. In a nutshell Seamless is biased towards Rapid Application Prototyping.
- Under the hood it tries to reify every single part of the object distribution process and its policies, so as to allow profiling and fine-tuning for optimizing performance and avoiding common distribution caveats. 

!!Enough Said: Death to Sockets

!!!Installation

To install and start playing around with Seamless evaluate the following code-snippet in your Workspace:

[[[
Gofer it
	url: 'http://ss3.gemstone.com/ss/Seamless';
	package: 'ConfigurationOfSeamless';
	load.

((Smalltalk at: #ConfigurationOfSeamless) project version: '0.4') load.
]]]

Seamless has been ported to Pharo 3.0. To install Pharo on your system follow the online instructions *here>http://pharo.org/download* or *here>http://get.pharo.org/*. Loading Seamless can be also done directly from the command line as follows:

[[[
./pharo-ui Pharo.image config \
          http://ss3.gemstone.com/ss/Seamless \
          ConfigurationOfSeamless \
          --install=0.4
]]]

Then in order to be able to initiate and respond requests from other images evaluate:

[[[
aDeamon := SeamlessDeamon 
		newDefaultWithGlobalAccess 
		startOn: 8080.
]]]

which again can be done directly from the command-line at start-up. 

To sum-up and to facilitate your deployments here is how you can download pharo, load Seamless and start the deamon in your prefered port from scratch:

[[[
wget -O- get.pharo.org | bash;
./pharo-ui Pharo.image config \
          http://ss3.gemstone.com/ss/Seamless \
          ConfigurationOfSeamless \
          --install=0.4 \
          eval "SeamlessDeamon newDefaultWithGlobalAccess startOn: 8080"
]]]

In order to follow the example in this chapter you will be needing two images,
listening to port 8080 (""peer1"" from now on) and 8081 (""peer2"" from now on) respectively.

''Note: eval under pharo-ui exits upon evaluation, fix -- whileTrue: [Processor yield] or smth''

!!!Hallo Transcript !

Once you have your peers set-up you can start sending messages from one to another. The simplest example would be to print the customary \'hallo world\' or a sequence of numbers from peer1 to the transcript of peer2. There are a lot of different ways to do that with Seamless let's see some of them (from peer1):

[[[
"sugar 1"
remoteTranscript := (Transcript from: '127.0.0.1:8081'). 
remoteTranscript open.
remoteTranscript show: 'Hallo World !'.
1 to: 100 do: [:i | 
	remoteTranscript show: i; cr.
].	
]]]

As you can see the only difference with printing locally is on line 2 when we retrieve the remote transcript instead of using the local Transcript of peer1.
We will come back to the trade-offs introduced to your code by this ''transperancy'' between local and remote execution. In the meantime here is some other ways you can retrieve a remote object and start sending messages to it with Seamless:

[[[
"sugar 2"
remoteTranscript := '127.0.0.1:8081' globalAt: #Transcript.
"sugar 3"
remoteEnvironment := '127.0.0.1:8081' asRemoteEnvironment.
remoteTranscript := remoteEnvironment at: #Transcript.
"sugar 4 (alt 1)"
remoteTranscript := (Smalltalk from: '127.0.0.1:8081') globals at: #Transcript.
]]]

This is of course all syntactic sugar with the seamless deamon and protocol working behind the scene to manage your remote references. You can even use these as a base to introduce your own abstractions for fetching remote objects.

At this point the curious reader may have noticed that the above code (especially syntactic sugar 4) implicitely means that a remote peer has full access to the SystemDictionary on the other side and whence the whole system. This is of course intentional and usefull for prototyping but of course rather perilous for deployment.

Remember when we where setting-up our seamless deamon we invoked:

[[[
SeamlessDeamon newDefaultWithGlobalAccess startOn: 8080
]]]

inside the SeamlessDeamon>>newDefaultWithGlobalAccess method (which we will be examining in detail in Section blah) the Smalltalk globals are given as the entry point of communication and the overall distribution policies are set to their most permissive state. 

Restricting which objects can be referenced from your image and how exactly they will behave is a matter of changing this entry point dictionary (to point to a user-defined one rather than the system dictionary) and altering the distribution policy of your deamon. 

''Note: clean up syntactic sugars and loose the SeamlessDeamonManager (just adds complexity) -- Also now that you have the logger expand this with passing implicit refs etc''

!!Between Ping-Pong and the REST

''Note: Before starting log the examples from previous section and say how traffic may be reduced -- Either move this one as a last example or reduce it''

Taking a hint from the logging results of our previous example we now move on to a more complicated case in order to better understand how proxies are generated and propagated in both directions as code is executed. Our goal is for the reader to be able to reason about the distribution of objects and structure code accordingly.

After that we will discuss the well-documented caveats of ''transparent distribution'' (ref here from ibm) and how this model compares to the the other end of the communication spectrum, namely that of stateless one-shot requests (REST). Then we will see how you can code and configure Seamless to move your implementation towards one or the other end of the spectrum.

In the first code snippet below (which you can find in the Examples sub-package of Seamless) we see the localPingPong method of the TutorialExample class. This method on line 2 creates a new instance of the PingPong class and sends the message \#decrement:using: to it.

[[[
1 TutorialExample class>>localPingPong
2	PingPong new decrement: 100 using: PingPong new.
]]]

The ping-pong instance through the \#decrement:using: method is responsible for decrementing the number ''aNumber'' which it receives as the first argument through mutual-recursion with another ping-pong instance (whence the name ping-pong). The number is decreased on line 6 as it is passed back and forth between the two instances, while on line 11 the number of each step is printed. Printing is done after the mutual recursive calls with each executing context (100 contexts in this example) printing the number it received and returning.

If you open a Transcript and execute ''TutorialExample localPingPong'' you will \- as expected \- see the count-down from 100 being printed on your screen.

[[[
1 PingPong>> decrement: aNumber using: aPingPongInstance
2	
3	aNumber = 0 ifFalse: [
4	
5		aPingPongInstance 
6			decrement: aNumber - 1 
7			using: self.
8		
9	].
10
11	Transcript show: aNumber; cr.
]]]

This rather abstract and boring example can become more intresting if one of the two instances is remote. This is achived on lines 2 and 3 of the \#pingPong method in the TutorialExample class (see below) where a local PingPong instance receives a remote instance of the same class as a second argument.

To run this example set-up peer1 and peer2 as previously and open the Transcripts on both sides. You should see that now \- in contrast with the local version \- only even numbers are printed on peer1 while odd numbers are printed on peer2.

In this case the hundred executing contexts which print the results before returning are coupled between the two machines. Naturally the first call to the local pingPong instance on line 3 below will wait for all contexts in both machines to return before printing 100. 

The first lesson here is that in this remote case ''waiting'' includes both the computation that is taking place (the decrement of the numbers) but also the communication overhead that the hundred remote calls will generate. The second point you should note is that this overhead was implicitely generated. We only ''explicitely'' sent one remote call from peer1 on lines 2 and 3 where we created a remote proxy to peer2. Then peer2 ''implicitely'' received a remote proxy from peer1 through line 7 of the \#decrement:using: method where self is passed as a second argument. This resulted in interwinded ping-pong calls generated in both directions. 

[[[
1 TutorialExample class>>pingPong
2	remotePingPongClass := ('127.0.0.1:8081' globalAt: #PingPong). 
3	PingPong new decrement: 100 using: remotePingPongClass new. 
]]]

By default Seamless chooses a handfull of classes to be passed or returned by value (ie copied) while all other local arguments to a remote call (or return values) will be passed by reference (implicitely creating proxies on the other side). As a simple rule you can think that by default ''basic objects'' such as numbers and strings are passed by value while more ''composite objects'' are passed by reference. The global default deamon of Seamless passes only the following classes by value:

- Boolean 
- Character 
- Number 
- String 
- Symbol 
- UndefinedObject 
- Color


Of course this list can be changed dynamically either while setting up your deamon or even (if needed) while your application is running. Even more conveniently you can programmatically choose to serialize a previously proxied object or ''force'' the serialization of a local object to the other side on a per instance basis.

To illustrate this consider the following two examples below. On the first example we have changed the pingPong method we saw earlier by sending the message \#asLocalObject to the remotePingPong instance we have created. This message send will actually return a copy of the remote pingPong instance, effectively serializing the proxied object. This will in turn result in a local-only execution of the \#decrement:using: method, since now both ping pong instances reside on the same machine. You can confirm this by running the following code and watching the whole sequence of numbers being printed only on peer1.

[[[
1 TutorialExample class>>pingPong
2	remotePingPongClass := ('127.0.0.1:8081' globalAt: #PingPong). 
3	PingPong new decrement: 100 using: remotePingPongClass new asLocalObject. 
]]]

Alternatively you could force the otherwise implicit proxy generated from peer1 to be passed by value as follows:

[[[
1 PingPong>> decrement: aNumber using: aPingPongInstance
2	
3	aNumber = 0 ifFalse: [
4	
5		aPingPongInstance 
6			decrement: aNumber - 1 
7			using: (By value: self).
8		
9	].
10
11	Transcript show: aNumber; cr.
]]]

The only thing that has changed here is the ''By value:'' directive on line 7 which will force the local ping pong instance of peer1 to be sent by copy to peer2. You can confirm this by running the code and watching the whole sequence of numbers (except the first) being printed only on peer2.

In all examples above we only had to add a one-liner or even a single message sent to make our initial mutual recursion to be distributed across two machines in different ways. The question of course here is how do you choose between the diffent approaches. More precissely how do you choose which objects to proxy and which objects to pass by value.

The answer to this is illustrated in the following figure. It turns out that the more objects or classes of objects you pass by value the more ''closer'' you are to a communication paradigm like REST where everything is passed as a copy and each call is a ''one-shot'' request against a simple communication API (that is uncoupled and does not generate implicit traffic).  On the contrary the more you rely on the implicit proxyfication of objects between calls the more closer you are to ''tranparent'' distribution and its documented caveats (strong coupling, latency, hard to debug). 

''NOTE: Figure Here''

The idea behind Seamless is that you should be able to play across the whole spectrum while you are prototyping and fine-tune your code by profiling and considering the trade-offs. Even more so you may even want to use Seamless to craft usefull abstractions that enforce certain paradigms to your code.  Hopefully by the end of this Chapter you will be able to do that by studying how middleware solutions like Seamless work under the hood.

 

''NOTE: why By value: and not byValue''

''NOTE: explain what the code does and say that this is a intentionally coupled example. Talk about REST do the diagram and then show asLocal (and how it breaks propagation), By value: and the Seamless configuration consider moving some of these discussions elsewhere''

- The ping-pong examples
- Make a diagram with transparent distribution
on one end REST on the other, explain the
controversy of transparent distribution (ref to IBM paper)
- Explain that in terms of proxyfication/serialization
everything is a subset of transparent distribution (make
analogy with Turing tarpit)
- Explain where OpenCorba, RMI are
- Explain that with Seamless you can be wherever you choose
on the spectrum, give an all serialized rest example

!!Practice Makes Perfect

- All the examples from the presentation

''NOTE: Actually put the contact example here''

!!Ok, ok: Make me a Remote Tester

- A simple remote testing application with Seamless

!!Ok, ok: Make me a Distributed Game

- Noury's application with Seamless

!!What's Under the Hood

- diagram from PhD ++ Seamless implementation part

!!How It All Works ?

- explain the different cases of distributing objects

!!Open Issues: Where Do We Go From Here ?

- More Doc/Tests
- Refactoring to Patterns (TM)
- Green Threading and UI
- Exception Handling
- Distributed-GC
- Futures (say here about batch communication execution and other optimizations)
- Monitoring

!!Acks






