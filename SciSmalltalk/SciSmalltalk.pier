! Code functionality assessment

@@note it would be good to show some example of ODE
@@note then it is important to think what the reader can learn from reading a chapter. For example it would be good to show some representatives of the Smark code. Another example would be to display the graphs with Graph-Et and to show the code so that if I have another problem I can reuse 

I'm a proud participant of the Google Summer of Code (*GSoC>https://developers.google.com/open-source/soc/*). My project was "SciSmalltalk - Solving Ordinary Differential Equations" (ODE) in Smalltalk.

So, my main task was to write the methods for solving *ODE>http://en.wikipedia.org/wiki/Ordinary_differential_equation*. It took me really a lot of time, but now there are 15 methods from which 4 are fourth-order, 3 are third-order, 6 are second-order and the rest 2 are first-order; seven methods are *explicit>http://en.wikipedia.org/wiki/Explicit_and_implicit_methods* and eight are implicit; nine are *multistep>http://en.wikipedia.org/wiki/Linear_multistep_method* methods.

I know that the last paragraph was boring. But this post is not about solving ODEs.  It's about understanding  is your code working the right way. I've ended up with 15 numerical methods and then I started to ask myself what is the difference between them. And in the next sections I want to describe the assessment I've made for my own work. So, keep reading because the fun is yet to come.

!!Quality criteria

Everyone knows about unit testing. We are writing the tests in order to check, that our methods work as we expect them to. This approach saves us money and time when something breaks. In this case we know exactly where to look for a mistake.

When it comes to numerical methods it's not enough to have correctly working methods. When you use numerical calculations another important criterion is the time of execution. To test my code for execution time I've written benchmarks for it (my tutorial on writing the benchmarks is *http://natalia.tymchuk.me/2013/09/hello.html>http://natalia.tymchuk.me/2013/09/hello.html*). It turns out, that these benchmarks have the same idea as the tests, but instead of returning the value of 'true' or 'false', they return the time of method execution. SMark, the framework for writing benchmarks also has a design similar to SUnit. Furthermore I have extended the functionality of SMark to generate XML reports which can be used by *Jenkins>http://en.wikipedia.org/wiki/Jenkins_(software)* to plot the results. Also I've added the support for visualizations and an option to run a several of test suites together.

Obviously, all methods give us a different execution time, and according to our previous quality criteria the best method is the one that is passing all unit tests and has the fastest execution time. This brings us to the conclusion that we have 14 useless method, or a bad criteria. In fact we forgot about the accuracy, because all the numerical method's solutions differ from the actual value that can be found by solving equation analytically.

 So I've created again something similar to SUnit, but this time it was calculating the deviation of a numerical method from the actual value. And again I've added a support for XML generation, visualization etc...

So using these automated tests helps you to stay updated with a quality changes of your code.
You will notice when the time of execution becomes twice as big because of an architecture refactoring, or the method's accuracy decreases dramatically because of performance optimizations.

Both benchmarks and accuracy infrastructure were very similar to SUnit, and this brings us to a question: maybe we need a bit broader set of tools in order to write the different kinds of the quality tests? Each separate tool will have to implement a way to write, run, report in different formats. Maybe we need a framework for writing a quality criteria tests?

!!Quality assessment

When you got the tools to calculate stats of your criteria, you can start to assess the quality of your methods. Here are the examples how to visualize this data.  

!!!Benchmarks trend

+Trends: showing the evolution of benchmarks>file://pictures/getPlot.png|width=50+


We can draw the trend of execution time with a simple line diagram. This gives us a possibility to see how it changes with the evolution of our application.


The image on left is from a CI server. It is very convenient to see how benchmarks change with each build.

""Pay attention"": the benchmark result (time) is changing not only when you change the function, but even when you rerun it. It depends on the computer (CPU clock speed), other running processes. That's why there may be a problem. For example, there is significant increasing of the values, shown on the next image.

+Picture 2>file://pictures/2.png|width=100+

 These results were produced by running tests in a virtual environment, which is capable of running several builds at the same time. So if you run such things on a virtual machine, it might be not accurate.

!!!Benchmarks bar diagram

Also benchmark results can be visualized depending on each other, not only on the time.
If you want to know the relation between the benchmark's result, you should use the bar graph:

+Picture 3>file://pictures/3.png|width=100+

The proportion almost does not change, so it's easier to look at the bar diagram than at the line diagram. Here you can see which method execution takes the most time, and which the least.
Some data you may want to see as statistics on server, but often you want to have live visual feedback on your computer to do what you need in the best way. In that case you can use *Graph-ET>http://www.youtube.com/watch?v=PkKNALQHa88*. It is a GSoC project written by Daniel Aviv Notario. You can use that framework to draw the graphs, to experiment with size, position, - everything that you have on your image and what you would like to add.

+Benchmarks in Graph-ET>file://pictures/4BenchmarksinGraph-ET.png|width=10+
 
In the case that your benchmark results are close to zero, it is necessary to increase the problemSize, which multiplies the results. Make the smallest your results greater or equal to 10.

+ProblemSize equal 100.>file://pictures/5ProblemSize equal 100.png|width=50+ 

+ProblemSize equal 1>file://pictures/6ProblemSize equal 1.png|width=50+
   
As you can see the results are similar, but not identical.

!!!Accuracy

The deviation can be plotted on CI server like the benchmarks. But the result is not affected by the machine workload, and if a graph has been changed, it indicates a change of code.

With a bar graph it could be a more interesting situation, because at first I got an image similar to this one:
 
+Picture 7>file://pictures/7.png|width=50+

 The problem was that step size, that I used, was so small, that every method returned almost the same result.
  The graph of accuracies with the larger step looks different :

+Accuracies in Graph-ET>file://pictures/8Accuracies in Graph-ET .png|width=50+
Accuracies in Graph-ET  


The biggest deviation comes from the Euler and Backward Euler methods, which are the first order methods. And the family of Adam-Moulton multistep methods (Trapezoid, AM3, AM4) returns the best results.


Now a question arises. How the deviation varies depending on the step size?


And it is one of the most interesting things.

On the image the darker colors  correspond to the smaller steps. We can see that the colors are distributed differently. It depends on how each method's result is close to the actual point. For example, the Euler and BackwardEuler methods are approaching to the point from one side, so the colors change smoothly.

+Picture 9>file://pictures/9.png|width=10+

An even more impressive thing is the dependence of accuracy on the initial state.

+Picture 10>file://pictures/10.png|width=10+

On the y-axis we have deviation between given and actual results. The intensity of the color displays the shift of initial value both positive or negative.
The shades of a blue color indicate the negative deviation, and the shades of red - the positive deviation.
The best methods are those, that at zero point have black colour. Because, the closer we are to the initial point (it is indicated with a black colour close to x-axis ), the closer we are to the actual value.

+Picture 11>file://pictures/11.jpg|width=10+

 As with previous images, the graphics of Euler and BackwardEuler methods are the simplest, with the colors that are changing gradually. However, exactly these methods draw the most attention, and from their graphs we can understand that they are not the best methods. This happens because, if we take the point (A0 - 1) as the initial one, than we will get a value less than A4 and closer to the function which is drawn with blue colour. 

+Picture 12:Euler method>file://pictures/12.png|width=10+

For the BackwardEuler method it's the same situation with initial point (A0 {{{+}}} 1). 

Those last two bar graphs are very exciting, because we can see live how the numerical methods work. As for me it's amazing.

!!!Benchmarks with Accuracies


In Graph-ET you even can merge the graphs of the benchmarks and the accuracies.

Benchmarks are measured in milliseconds, and the accuracies are just the numbers. Therefore, to merge it correctly, we converted all values ​​to percentages.

+Picture 13>file://pictures/13.png|width=10+

In this image accuracy is red and benchmark's time is blue.

It's important and interesting, because we can see both the most accurate and the quickest methods. As a result we can determine which method is the best for our ODE.
